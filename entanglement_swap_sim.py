import pandas
import pydynaa as pd
import netsquid as ns
from netsquid.components import SourceStatus, Clock, GaussianDelayModel
from netsquid.components import QuantumChannel
from netsquid.components import QuantumProcessor, T1T2NoiseModel, PhysicalInstruction
from netsquid.components.models import FibreDelayModel
from netsquid.nodes import Network
from netsquid.protocols import Signals
from netsquid.qubits import StateSampler, QFormalism, ketstates as ks
from netsquid.util.datacollector import DataCollector

from qsource import QSource                                                                                             # use localy modified version of QSource
from FibreLossModel import FibreLossModel
# from FreeSpaceErrorModel import FreeSpaceErrorModel
from SimulationProtocol import SimulationProtocol


def setup_network(source_attempts,
                  memory_depth,
                  **kwargs):

    # retrieve setup parameters from sim_params, substituting defaults when required
    source_frequency = kwargs.get('source_frequency', 100e6)
    channel_A_length = kwargs.get('channel_A_length', 1)
    channel_A_static_loss = kwargs.get('channel_A_static_loss', 0)
    channel_A_loss = kwargs.get('channel_A_loss', 0)
    channel_A_speed = kwargs.get('channel_A_speed', 3e5)
    channel_B_length = kwargs.get('channel_B_length', 1)
    channel_B_static_loss = kwargs.get('channel_B_static_loss', 0)
    channel_B_loss = kwargs.get('channel_B_loss', 0)
    channel_B_speed = kwargs.get('channel_B_speed', 3e5)
    memory_T1 = kwargs.get('memory_T1', 1.0e8)
    memory_T2 = kwargs.get('memory_T2', 1.0e4)
    physical_instructions = kwargs.get('physical_instructions', None)



    # find each channel's propagation time [ns]:
    propagation_time_A = (channel_A_length / channel_A_speed) * 1e9
    propagation_time_B = (channel_B_length / channel_B_speed) * 1e9

    if propagation_time_A < propagation_time_B:
        clock_A_delay = propagation_time_B - propagation_time_A
        clock_B_delay = 0
        clock_R_delay = propagation_time_B
    elif propagation_time_A > propagation_time_B:
        clock_A_delay = 0
        clock_B_delay = propagation_time_A - propagation_time_B
        clock_R_delay = propagation_time_A
    else:
        clock_A_delay = 0
        clock_B_delay = 0
        clock_R_delay = propagation_time_A                                                                              # arbitrary choice since matched time

    source_period = 1e9 / source_frequency                                                                              # source period [ns]
    clock_model = {'timing_model': GaussianDelayModel(delay_mean=source_period, delay_std=0.00)}

    channel_A_model = {'quantum_loss_model':
                           FibreLossModel(loss_init=channel_A_static_loss, p_loss_length=channel_A_loss),
                       'delay_model':
                           FibreDelayModel(c=channel_A_speed)}                                                          # define channel_A_model according to passed sim_params

    channel_B_model = {'quantum_loss_model':
                           FibreLossModel(loss_init=channel_B_static_loss, p_loss_length=channel_B_loss),
                       'delay_model':
                           FibreDelayModel(c=channel_B_speed)}                                                          # define channel_B_model according to passed sim_params

    memory_model = T1T2NoiseModel(memory_T1, memory_T2)



    network = Network('Entanglement_swap')
    node_a, node_b, node_r = network.add_nodes(['node_A', 'node_B', 'node_R'])

    state_sampler = StateSampler(qs_reprs=[ks.s11], probabilities=[1.0], formalism=QFormalism.DM)                        # define desired states to be generated by source

    # Setup end node A:
    source_a = QSource(name='QSource_node_A',
                       state_sampler=state_sampler,
                       num_ports=2,
                       status=SourceStatus.EXTERNAL,
                       properties={'is_number_state': False},                                                           # FIXME: WHY IS THIS USED AGAIN?, seems that we can decay qubit state just fine in memory
                       output_meta={'qm_replace': True, 'qm_positions': [0]})                                           # allow incoming qubits to replace anything in slot 0, recall we use the default slots only to sort into slots with QProgram
    clock_a = Clock(name='Clock_node_A', models=clock_model, start_delay=clock_A_delay, max_ticks=source_attempts)                                        # "max_ticks" will timeout the program after desired number of connection attempts
    node_a.add_subcomponent(source_a)
    node_a.add_subcomponent(clock_a)

    # Setup end node B:
    source_b = QSource(name='QSource_node_B',
                       state_sampler=state_sampler,
                       num_ports=2,
                       status=SourceStatus.EXTERNAL,
                       properties={'is_number_state': False},
                       output_meta={'qm_replace': True, 'qm_positions': [1]})                                                                # allow incoming qubits to replace anything in slot 1, recall we use the default slots only to sort into slots with QProgram
    clock_b = Clock(name='Clock_node_B', models=clock_model, start_delay=clock_B_delay, max_ticks=source_attempts)                                        # "max_ticks" will timeout the program after desired number of connection attempts
    node_b.add_subcomponent(source_b)
    node_b.add_subcomponent(clock_b)

    # Setup midpoint repeater node R:
    if memory_depth == 0:                                                                                               # special case, initialize non-physical processor to handle measurement on simultaneous input
        total_positions = 2
        qprocessor_r = QuantumProcessor(name='QProcessor_R',
                                  num_positions=total_positions,
                                  fallback_to_nonphysical=True,
                                  phys_instructions=None,
                                  memory_noise_models=None)
    else:
        total_positions = memory_depth*2 + 2
        qprocessor_r = QuantumProcessor(name='QProcessor_R',
                                  num_positions=total_positions,
                                  fallback_to_nonphysical=True,
                                  phys_instructions=physical_instructions,
                                  memory_noise_models=memory_model)

    if memory_depth != 0:                                                                                               # initialization of memories
        for position in qprocessor_r.mem_positions[2: memory_depth+2]:
            memory_default, = ns.qubits.create_qubits(1, no_state=True)
            ns.qubits.assign_qstate([memory_default], ns.h0, formalism=QFormalism.DM)
            position.add_property('origin', value=node_a.name)                                                          # first half of qmemory is allocated for qubits from node_A
            position.set_qubit(memory_default)                                                                          # initialize to default state
            position.in_use = False
            position.add_property(name='status', value="IDLE")
        for position in qprocessor_r.mem_positions[memory_depth+2:]:
            memory_default, = ns.qubits.create_qubits(1, no_state=True)
            ns.qubits.assign_qstate([memory_default], ns.h0, formalism=QFormalism.DM)
            position.add_property('origin', value=node_b.name)                                                          # second half of qmemory is allocated for qubits from node_B
            position.set_qubit(memory_default)                                                                          # initialize to default state
            position.in_use = False
            position.add_property(name='status', value="IDLE")

        qprocessor_r.set_position_used(True, position=0)                                                                # flag as used, never accessed for storage, used as holding location to sort into memory
        qprocessor_r.set_position_used(True, position=1)                                                                # flag as used, never accessed for storage

    node_r.add_subcomponent(qprocessor_r)

    clock_r = Clock(name='Clock_node_R', models=clock_model, start_delay=clock_R_delay, max_ticks=source_attempts)
    node_r.add_subcomponent(clock_r)

    # Setup quantum channels:
    qchannel_ar = QuantumChannel(name='QChannel_A->R',
                                 length=channel_A_length,
                                 models=channel_A_model)
    port_name_a, port_name_ra = network.add_connection(node_a, node_r, channel_to=qchannel_ar, label='quantum',
                                                       port_name_node1='conn|A->R|', port_name_node2='conn|R<-A|')
    qchannel_br = QuantumChannel(name='QChannel_B->R',
                                 length=channel_B_length,
                                 models=channel_B_model)
    port_name_b, port_name_rb = network.add_connection(node_b, node_r, channel_to=qchannel_br, label='quantum',
                                                       port_name_node1='conn|B->R|', port_name_node2='conn|R<-B|')
    # Setup Alice ports:
    node_a.subcomponents['QSource_node_A'].ports['qout0'].forward_output(node_a.ports[port_name_a])

    # Setup Bob ports:
    node_b.subcomponents['QSource_node_B'].ports['qout0'].forward_output(node_b.ports[port_name_b])

    # Set up Repeater ports:
    node_r.ports[port_name_ra].forward_input(node_r.subcomponents['QProcessor_R'].ports['qin0'])                        # incoming qubits on QChannel_A->R go to slot 0
    node_r.ports[port_name_rb].forward_input(node_r.subcomponents['QProcessor_R'].ports['qin1'])                        # incoming qubits on QChannel_B->R go to slot 1'

    return network


def sim_setup(network, source_config, memory_config):
    simulation = SimulationProtocol(network.get_node('node_A'),
                                    network.get_node('node_B'),
                                    network.get_node('node_R'),
                                    source_config,
                                    memory_config)                                                                       # initialize protocol to handle simulation events

    def record_run(evexpr):
        # Record run
        protocol = evexpr.triggered_events[-1].source
        result = protocol.get_signal_result(Signals.SUCCESS)
        return result

    dc = DataCollector(record_run, include_time_stamp=False, include_entity_name=False)                                 # data collection object to handle storage of results for each run
    dc.collect_on(pd.EventExpression(source=simulation, event_type=Signals.SUCCESS.value))                              # store result of "Success" signal into data collector

    return simulation, dc


def run_simulation(sim_params, attempts, memory_depths):
    simulation_data = pandas.DataFrame()
    for memory_depth in memory_depths:
        ns.sim_reset()                                                                                                  # reset simulation stats/time each run
        ns.set_qstate_formalism(QFormalism.DM)                                                                          # set formalism to ensure noise/error is calculated accurately
        # phys_instructions = [PhysicalInstruction(instr.INSTR_MEASURE_BELL, duration=5.0, parallel=True)]              # FIXME: possibly for later use

        network = setup_network(source_attempts=attempts,
                                memory_depth=memory_depth,
                                **sim_params)                                                                           # describe network parameters as given in sim_params

        source_config = {
            'probability_emission': sim_params['probability_emission']
        }

        if memory_depth == 0:                                                                                           # variable to determine which function to run in RepeaterProtocol
            use_memory = False
        else:
            use_memory = True
        memory_config = {
            'use_memory': use_memory,
            'reset_period_cycles': sim_params['memory_reset_period'],
            'reset_duration_cycles': sim_params['memory_reset_duration'],
            'probability_detection': sim_params['probability_detection']
        }
        entangle_sim, dc = sim_setup(network, source_config, memory_config)
        entangle_sim.start()
        stats = ns.sim_run()                                                                                            # run until out of attempts on source clocks

        if dc.dataframe.empty:                                                                                          # build df for case with no successes
            data = [{'Memory Depth': memory_depth,
                     'num_meas': 0,
                     # 'fid_q1': None,
                     # 'fid_q2': None,
                     'fid_joint': None}]
            df = pandas.DataFrame(data)
        else:                                                                                                           # build df for each run from data collector
            # fid_q1 = dc.dataframe['fid_q1'].mean()                                                                      # avg fidelity of qubits used from node A
            # fid_q2 = dc.dataframe['fid_q2'].mean()                                                                      # avg fidelity of qubits used from node B
            fid_joint = dc.dataframe['fid_joint'].mean()                                                                # avg joint fidelity
            num_meas = len(dc.dataframe)                                                                                # number of measurement events during run
            mem_use_A = dc.dataframe['pos_A'].value_counts()
            mem_use_B = dc.dataframe['pos_B'].value_counts()
            mem_use = mem_use_A.append(mem_use_B)                                                                       # FIXME: for future use, tracking which mem slots are used
            data = [{'Memory Depth': memory_depth,
                     'num_meas': num_meas,
                     # 'fid_q1': fid_q1,
                     # 'fid_q2': fid_q2,
                     'fid_joint': fid_joint}]

            df = pandas.DataFrame(data)                                                                                 # pack data on each run in df
        simulation_data = simulation_data.append(df)                                                                    # append df for each run to simulation data
    return simulation_data


def repeat_simulation(sim_params, attempts, iterations, memory_depths):                                                 # run simulation for given amount of iterations
    total_data = pandas.DataFrame()
    for iteration in range(iterations):
        simulation_data = run_simulation(sim_params, attempts, memory_depths)
        simulation_data.insert(0, 'iteration', iteration)
        print(f"ON ITERATION: {iteration}")
        print(simulation_data)
        total_data = total_data.append(simulation_data)                                                                 # compile data from each iteration into total_data
    return total_data


def create_plot(sim_params, attempts, iterations, memory_depths):
    from matplotlib import pyplot as plt
    total_data = repeat_simulation(sim_params, attempts, iterations, memory_depths)                                     # gather simulation data

    # avg_data = total_data.groupby('Memory Depth')[['num_meas', 'fid_q1', 'fid_q2', 'fid_joint']].agg(
    #     {'num_meas': ['mean', 'std'],
    #      'fid_q1': ['mean', 'std'],
    #      'fid_q2': ['mean', 'std'],
    #      'fid_joint': ['mean', 'std']}).reset_index()                                                                   # compute average and std of data over all iterations

    avg_data = total_data.groupby('Memory Depth')[['num_meas', 'fid_joint']].agg(
        {'num_meas': ['mean', 'std'],
         'fid_joint': ['mean', 'std']}).reset_index()  # compute average and std of data over all iterations

    fig = plt.figure()
    fig.set_size_inches(16,9)

    # Plot # measurements vs memory depth
    ax = plt.subplot(2,2,1)
    plt.bar(avg_data['Memory Depth'], avg_data['num_meas']['mean'], yerr=avg_data['num_meas']['std'],
            width=0.5, capsize=10, color='g',ecolor='k')
    plt.xlabel("Memory Depth (per connection)")
    plt.ylabel("# of (possible) Measurements")
    plt.ylim([0,attempts])
    plt.xticks(memory_depths, memory_depths)
    plt.setp(ax.get_xticklabels()[1::2], visible=False)
    plt.title("Number Measurements vs Memory Depth")

    # Plot avg fidelity data vs memory depth
    ax = plt.subplot(2,2,2)
    # plt.errorbar(avg_data['Memory Depth'], avg_data['fid_q1']['mean'], yerr=avg_data['fid_q1']['std'],
    #              capsize=4, ecolor='k', fmt='bo-', markersize=4, label='Fidelity from node A')
    # plt.errorbar(avg_data['Memory Depth'], avg_data['fid_q2']['mean'], yerr=avg_data['fid_q2']['std'],
    #              capsize=4, ecolor='k', fmt='rs--', markersize=4, label='Fidelity from node B')
    plt.errorbar(avg_data['Memory Depth'], avg_data['fid_joint']['mean'], yerr=avg_data['fid_joint']['std'],
                 capsize=4, ecolor='k', fmt='gd-.', markersize=4, label='Joint Fidelity')
    plt.xlabel("Memory Depth (per connection)")
    plt.ylabel("Avg. Fidelity (v.s. expected state)")
    plt.ylim([0,1.05])
    plt.xticks(memory_depths, memory_depths)
    plt.setp(ax.get_xticklabels()[1::2], visible=False)
    plt.grid(True)
    plt.title("Avg. Fidelity vs Memory Depth per connection")
    plt.legend()

    # Generate table to report sim_params
    ax = plt.subplot(2,1,2)
    table_data = [["Source Configuration", "Frequency (MHz)", sim_params['source_frequency']/1e6],
                  ["", "Probability of emission (%)", sim_params['probability_emission']],
                  ["Channel A Configuration", "Length (km)", sim_params['channel_A_length']],
                  ["", "Static Loss (dB)", sim_params['channel_A_static_loss']],
                  ["", "Loss (dB/km)", sim_params['channel_A_loss']],
                  ["Channel B Configuration", "Length (km)", sim_params['channel_B_length']],
                  ["", "Static Loss (dB)", sim_params['channel_B_static_loss']],
                  ["", "Loss (dB/km)", sim_params['channel_B_loss']],
                  ["Memory Configuration", "T1 (ns)", sim_params['memory_T1']],
                  ["", "T1 (ns)", sim_params['memory_T2']],
                  ["", "Reset Period (# cycles)", sim_params['memory_reset_period']],
                  ["", "Reset Duration (# cycles)", sim_params['memory_reset_duration']],
                  ["", "Probability of detection (%)", sim_params['probability_detection']]]

    table = plt.table(cellText=table_data,
                      cellLoc='left',
                      loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(0.6,1.0)
    plt.title("Parameters", y=-0.05)
    ax.axis('off')
    plt.show()



sim_params = {
    'source_frequency': 100e6,      # [hz]      : fixed emission rate for both end node sources
    'probability_emission': 90,    # [%]       : probability of successful photon emission for end node sources
    'channel_A_length': 7,          # [km]      : length of channel_A, [node_a ---> node_r]
    'channel_A_static_loss': 5.0,   # [dB]      : fixed loss of channel_A (i.e. coupling losses etc.), results in dropping photon
    'channel_A_loss': 0.2,          # [dB/km]   : loss per km of channel_A, results in dropping photon
    'channel_A_speed': 3e5,         # [km/s]    : transmission speed of channel_A
    'channel_B_length': 50,         # [km]      : length of channel_B, [node_r <--- node_b]
    'channel_B_static_loss': 5.0,   # [dB]      : fixed loss of channel_B (i.e. coupling losses etc.), results in dropping photon
    'channel_B_loss': 0.2,          # [dB/km]   : loss per km of channel_B, results in dropping photon
    'channel_B_speed': 3e5,         # [km/s]    : transmission speed of channel_B
    'memory_T1': 1.0e4,             # [ns]      : relaxation time of quantum memory state (WARNING: must have T1 > T2)
    'memory_T2': 0.5e4,             # [ns]      : dephasing time of quantum memory state (WARNING: must have T1 > T2)
    'memory_reset_period': 50,     # [cycles]  : number of clock cycles (at universally set frequency), until reset is automatically triggered
    'memory_reset_duration': 100,   # [cycles]  : number of clock cycles (at universally set frequency), until reset is completed
    'probability_detection': 90    # [%]       : probability of successful detection after interacting with memory
}

memory_depths = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,30,40,50]
attempts = 10000
iterations = 5

create_plot(sim_params, attempts, iterations, memory_depths)
ns.sim_reset()