import pandas
import pydynaa as pd
import netsquid as ns
from netsquid.components import SourceStatus, Clock, GaussianDelayModel
from netsquid.components import QuantumChannel
from netsquid.components import QuantumProcessor, T1T2NoiseModel, PhysicalInstruction
from netsquid.components.models import FibreDelayModel
from netsquid.nodes import Network
from netsquid.protocols import Signals
from netsquid.qubits import StateSampler, QFormalism, ketstates as ks
from netsquid.util.datacollector import DataCollector

from qsource import QSource                                                                                             # use localy modified version of QSource
from FibreLossModel import FibreLossModel
# from FreeSpaceErrorModel import FreeSpaceErrorModel
from SimulationProtocol import SimulationProtocol


def setup_network(source_attempts,
                  memory_depth,
                  **kwargs):

    # retrieve setup parameters from sim_params, substituting defaults when required
    source_frequency = kwargs.get('source_frequency', 100e6)
    channel_A_length = kwargs.get('channel_A_length', 1)
    channel_A_loss = kwargs.get('channel_A_loss', 0)
    channel_A_speed = kwargs.get('channel_A_speed', 3e5)
    channel_B_length = kwargs.get('channel_B_length', 1)
    channel_B_loss = kwargs.get('channel_B_loss', 0)
    channel_B_speed = kwargs.get('channel_B_speed', 3e5)
    memory_T1 = kwargs.get('memory_T1', 1.0e8)
    memory_T2 = kwargs.get('memory_T2', 1.0e4)
    physical_instructions = kwargs.get('physical_instructions', None)



    # find each channel's propagation time [ns]:
    propagation_time_A = (channel_A_length / channel_A_speed) * 1e9
    propagation_time_B = (channel_B_length / channel_B_speed) * 1e9

    if propagation_time_A < propagation_time_B:
        clock_A_delay = propagation_time_B - propagation_time_A
        clock_B_delay = 0
        clock_R_delay = propagation_time_B
    elif propagation_time_A > propagation_time_B:
        clock_A_delay = 0
        clock_B_delay = propagation_time_A - propagation_time_B
        clock_R_delay = propagation_time_A
    else:
        clock_A_delay = 0
        clock_B_delay = 0
        clock_R_delay = propagation_time_A                                                                              # arbitrary choice since matched time

    source_period = 1e9 / source_frequency                                                                              # source period [ns]
    clock_model = {'timing_model': GaussianDelayModel(delay_mean=source_period, delay_std=0.00)}

    coupling_loss = 5.0                                                                                                 # Typical coupling loss [dB]
    channel_A_model = {'quantum_loss_model':
                           FibreLossModel(loss_init=coupling_loss, p_loss_length=channel_A_loss),
                       'delay_model':
                           FibreDelayModel(c=channel_A_speed)}                                                          # define channel_A_model according to passed sim_params

    channel_B_model = {'quantum_loss_model':
                           FibreLossModel(loss_init=coupling_loss, p_loss_length=channel_B_loss),
                       'delay_model':
                           FibreDelayModel(c=channel_B_speed)}                                                          # define channel_B_model according to passed sim_params

    memory_model = T1T2NoiseModel(memory_T1, memory_T2)



    network = Network('Entanglement_swap')
    node_a, node_b, node_r = network.add_nodes(['node_A', 'node_B', 'node_R'])

    state_sampler = StateSampler(qs_reprs=[ks.y0], probabilities=[1.0], formalism=QFormalism.DM)                        # define desired states to be generated by source  # FIXME: Must make so that sometimes NOTHING is sent

    # Setup end node A:                                                                                                 # for future versions can add qmemory/qproc here too!
    source_a = QSource(name='QSource_node_A',
                       state_sampler=state_sampler,
                       num_ports=1,
                       status=SourceStatus.EXTERNAL,
                       properties={'is_number_state': False},                                                           # FIXME: WHY IS THIS USED AGAIN?, seems that we can decay qubit state just fine in memory
                       output_meta={'qm_replace': True, 'qm_positions': [0]})                                           # allow incoming qubits to replace anything in slot 0, recall we use the default slots only to sort into slots with QProgram
    clock_a = Clock(name='Clock_node_A', models=clock_model, start_delay=clock_A_delay, max_ticks=source_attempts)                                        # "max_ticks" will timeout the program after desired number of connection attempts
    clock_a.ports['cout'].connect(source_a.ports['trigger'])                                                            # external clock triggers source
    node_a.add_subcomponent(source_a)
    node_a.add_subcomponent(clock_a)

    # Setup end node B:                                                                                                 # for future versions can add qmemory/qproc here too!
    source_b = QSource(name='QSource_node_B',
                       state_sampler=state_sampler,
                       num_ports=1,
                       status=SourceStatus.EXTERNAL,
                       properties={'is_number_state': False},                                                           # set source to generate 'number_state' qubits. aka photons
                       output_meta={'qm_replace': True, 'qm_positions': [1]})                                                                # allow incoming qubits to replace anything in slot 1, recall we use the default slots only to sort into slots with QProgram
    clock_b = Clock(name='Clock_node_B', models=clock_model, start_delay=clock_B_delay, max_ticks=source_attempts)                                        # "max_ticks" will timeout the program after desired number of connection attempts
    clock_b.ports['cout'].connect(source_b.ports['trigger'])                                                            # external clock triggers source
    node_b.add_subcomponent(source_b)
    node_b.add_subcomponent(clock_b)

    # Setup midpoint repeater node R:
    if memory_depth == 0:                                                                                               # special case, initialize non-physical processor to handle measurement on simultaneous input
        total_positions = 2
        qprocessor_r = QuantumProcessor(name='QProcessor_R',
                                  num_positions=total_positions,
                                  fallback_to_nonphysical=True,
                                  phys_instructions=None,
                                  memory_noise_models=None)
    else:
        total_positions = memory_depth*2 + 2
        qprocessor_r = QuantumProcessor(name='QProcessor_R',
                                  num_positions=total_positions,
                                  fallback_to_nonphysical=True,
                                  phys_instructions=physical_instructions,
                                  memory_noise_models=None)                                                             # FIXME: Source of error in repeater protocol, temporarily assigning None in order to get further processes working

    # FIXME: marking as used/unusued may not be useful after implementing logic to write using gates

    if memory_depth != 0:                                                                                               # initialization of memories
        for position in qprocessor_r.mem_positions[2: memory_depth+2]:
            memory_default, = ns.qubits.create_qubits(1, no_state=True)
            ns.qubits.assign_qstate([memory_default], ns.h0, formalism=QFormalism.DM)
            position.add_property('origin', value=node_a.name)                                                          # first half of qmemory is allocated for qubits from node_A
            position.set_qubit(memory_default)                                                                          # initialize to default state
            position.in_use = False
            position.add_property(name='status', value="IDLE")
        for position in qprocessor_r.mem_positions[memory_depth+2:]:
            memory_default, = ns.qubits.create_qubits(1, no_state=True)
            ns.qubits.assign_qstate([memory_default], ns.h0, formalism=QFormalism.DM)
            position.add_property('origin', value=node_b.name)                                                          # second half of qmemory is allocated for qubits from node_B
            position.set_qubit(memory_default)                                                                          # initialize to default state
            position.in_use = False
            position.add_property(name='status', value="IDLE")

        qprocessor_r.set_position_used(True, position=0)                                                                # flag as used, never accessed for storage, used as holding location to sort into memory
        qprocessor_r.set_position_used(True, position=1)                                                                # flag as used, never accessed for storage

    node_r.add_subcomponent(qprocessor_r)

    clock_r = Clock(name='Clock_node_R', models=clock_model, start_delay=clock_R_delay, max_ticks=source_attempts)
    node_r.add_subcomponent(clock_r)

    # Setup quantum channels:
    qchannel_ar = QuantumChannel(name='QChannel_A->R',
                                 length=channel_A_length,
                                 models=channel_A_model)
    port_name_a, port_name_ra = network.add_connection(node_a, node_r, channel_to=qchannel_ar, label='quantum',
                                                       port_name_node1='conn|A->R|', port_name_node2='conn|R<-A|')
    qchannel_br = QuantumChannel(name='QChannel_B->R',
                                 length=channel_B_length,
                                 models=channel_B_model)
    port_name_b, port_name_rb = network.add_connection(node_b, node_r, channel_to=qchannel_br, label='quantum',
                                                       port_name_node1='conn|B->R|', port_name_node2='conn|R<-B|')
    # Setup Alice ports:
    node_a.subcomponents['QSource_node_A'].ports['qout0'].forward_output(node_a.ports[port_name_a])

    # Setup Bob ports:
    node_b.subcomponents['QSource_node_B'].ports['qout0'].forward_output(node_b.ports[port_name_b])

    # Set up Repeater ports:
    node_r.ports[port_name_ra].forward_input(node_r.subcomponents['QProcessor_R'].ports['qin0'])                        # incoming qubits on QChannel_A->R go to slot 0
    node_r.ports[port_name_rb].forward_input(node_r.subcomponents['QProcessor_R'].ports['qin1'])                        # incoming qubits on QChannel_B->R go to slot 1'

    return network


def sim_setup(network, memory_config):
    simulation = SimulationProtocol(network.get_node('node_A'),
                                    network.get_node('node_B'),
                                    network.get_node('node_R'),
                                    memory_config)                                                                       # initialize protocol to handle simulation events

    def record_run(evexpr):
        # Record run
        protocol = evexpr.triggered_events[-1].source
        result = protocol.get_signal_result(Signals.SUCCESS)
        return result

    dc = DataCollector(record_run, include_time_stamp=False, include_entity_name=False)                                 # data collection object to handle storage of results for each run
    dc.collect_on(pd.EventExpression(source=simulation, event_type=Signals.SUCCESS.value))                              # store result of "Success" signal into data collector

    return simulation, dc


def run_simulation(sim_params, attempts, memory_depths):
    simulation_data = pandas.DataFrame()
    for memory_depth in memory_depths:
        ns.sim_reset()                                                                                                  # reset simulation stats/time each run
        ns.set_qstate_formalism(QFormalism.DM)                                                                          # set formalism to ensure noise/error is calculated accurately
        # phys_instructions = [PhysicalInstruction(instr.INSTR_MEASURE_BELL, duration=5.0, parallel=True)]              # FIXME: possibly for later use

        network = setup_network(source_attempts=attempts,
                                memory_depth=memory_depth,
                                **sim_params)                                                                           # describe network parameters as given in sim_params

        if memory_depth == 0:                                                                                           # variable to determine which function to run in RepeaterProtocol
            use_memory = False
        else:
            use_memory = True
        mem_config = {
            'use_memory': use_memory,
            'reset_period_cycles': sim_params['memory_reset_period'],
            'reset_duration_cycles': sim_params['memory_reset_duration'],
            'prob_detection': sim_params['probability_detection']
        }
        entangle_sim, dc = sim_setup(network, mem_config)
        entangle_sim.start()
        stats = ns.sim_run()                                                                                            # run until out of attempts on source clocks

        if dc.dataframe.empty:                                                                                          # build df for case with no successes
            data = [{'Memory Depth': memory_depth,
                     'num_meas': 0,
                     'fid_q1': None,
                     'fid_q2': None,
                     'fid_joint': None}]
            df = pandas.DataFrame(data)
        else:                                                                                                           # build df for each run from data collector
            fid_q1 = dc.dataframe['fid_q1'].mean()                                                                      # avg fidelity of qubits used from node A
            fid_q2 = dc.dataframe['fid_q2'].mean()                                                                      # avg fidelity of qubits used from node B
            fid_joint = dc.dataframe['fid_joint'].mean()                                                                # avg joint fidelity
            num_meas = len(dc.dataframe)                                                                                # number of measurement events during run
            mem_use_A = dc.dataframe['pos_A'].value_counts()
            mem_use_B = dc.dataframe['pos_B'].value_counts()
            mem_use = mem_use_A.append(mem_use_B)                                                                       # FIXME: for future use, tracking which mem slots are used
            data = [{'Memory Depth': memory_depth,
                     'num_meas': num_meas,
                     'fid_q1': fid_q1,
                     'fid_q2': fid_q2,
                     'fid_joint': fid_joint}]

            df = pandas.DataFrame(data)                                                                                 # pack data on each run in df
        simulation_data = simulation_data.append(df)                                                                    # append df for each run to simulation data
    return simulation_data


def repeat_simulation(sim_params, attempts, iterations, memory_depths):                                                 # run simulation for given amount of iterations
    total_data = pandas.DataFrame()
    for iteration in range(iterations):
        simulation_data = run_simulation(sim_params, attempts, memory_depths)
        simulation_data.insert(0, 'iteration', iteration)
        print(f"ON ITERATION: {iteration}")
        print(simulation_data)
        total_data = total_data.append(simulation_data)                                                                 # compile data from each iteration into total_data
    return total_data


def create_plot(sim_params, attempts, iterations, memory_depths):
    from matplotlib import pyplot as plt
    total_data = repeat_simulation(sim_params, attempts, iterations, memory_depths)                                     # gather simulation data
    # total_data.to_csv('/Users/nickmccartney/Desktop/total_data.csv')                                                  # FIXME: Make system agnostic
    avg_data = total_data.groupby('Memory Depth')[['num_meas', 'fid_q1', 'fid_q2', 'fid_joint']].agg(
        {'num_meas': ['mean', 'std'],
         'fid_q1': ['mean', 'std'],
         'fid_q2': ['mean', 'std'],
         'fid_joint': ['mean', 'std']}).reset_index()                                                                   # compute average and std of data over all iterations
    # avg_data.to_csv('/Users/nickmccartney/Desktop/avg_data.csv')                                                      # FIXME: Make system agnostic

    fig = plt.figure()
    fig.set_size_inches(16,6)

    # Plot # measurements vs memory depth
    ax = plt.subplot(2,2,1)
    plt.bar(avg_data['Memory Depth'], avg_data['num_meas']['mean'], yerr=avg_data['num_meas']['std'],
            width=0.5, capsize=10, color='g',ecolor='k')
    plt.xlabel("Memory Depth (per connection)")
    plt.ylabel("# of (possible) Measurements")
    plt.ylim([0,attempts])
    plt.xticks(memory_depths, memory_depths)
    plt.setp(ax.get_xticklabels()[1::2], visible=False)
    plt.title("Number Measurements vs Memory Depth")

    # Plot avg fidelity data vs memory depth
    ax = plt.subplot(2,2,2)
    plt.errorbar(avg_data['Memory Depth'], avg_data['fid_q1']['mean'], yerr=avg_data['fid_q1']['std'],
                 capsize=4, ecolor='k', fmt='bo-', markersize=4, label='Fidelity from node A')
    plt.errorbar(avg_data['Memory Depth'], avg_data['fid_q2']['mean'], yerr=avg_data['fid_q2']['std'],
                 capsize=4, ecolor='k', fmt='rs--', markersize=4, label='Fidelity from node B')
    plt.errorbar(avg_data['Memory Depth'], avg_data['fid_joint']['mean'], yerr=avg_data['fid_joint']['std'],
                 capsize=4, ecolor='k', fmt='gd-.', markersize=4, label='Joint Fidelity')
    plt.xlabel("Memory Depth (per connection)")
    plt.ylabel("Avg. Fidelity (v.s. expected state)")
    plt.ylim([0,1.05])
    plt.xticks(memory_depths, memory_depths)
    plt.setp(ax.get_xticklabels()[1::2], visible=False)
    plt.grid(True)
    plt.title("Avg. Fidelity vs Memory Depth per connection")
    plt.legend()

    # Generate table to report sim_params
    ax = plt.subplot(2,1,2)
    table_data = [["Frequency (MHz)", "", sim_params['source_frequency']/1e6],
                  ["Channel A", "Length (km)", sim_params['channel_A_length']],
                  ["", "Loss (dB/km)", sim_params['channel_A_loss']],
                  ["Channel B", "Length (km)", sim_params['channel_B_length']],
                  ["", "Loss (dB/km)", sim_params['channel_B_loss']],
                  ["Memory", "T1 (ns)", sim_params['memory_T1']],
                  ["", "T1 (ns)", sim_params['memory_T2']],
                  ["", "Reset Period (# cycles)", sim_params['memory_reset_period']],
                  ["", "Reset Duration (# cycles)", sim_params['memory_reset_duration']],
                  ["", "Probability of detection (%)", sim_params['probability_detection']]]

    table = plt.table(cellText=table_data,
                      cellLoc='left',
                      loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(0.6,1.0)
    plt.title("Parameters", y=-0.01)
    ax.axis('off')
    plt.show()



sim_params = {
    'source_frequency': 100e6,      # [hz]
    'channel_A_length': 7,         # [km]
    'channel_A_loss': 0.2,          # [dB/km]
    'channel_A_speed': 3e5,         # [km/s]
    'channel_B_length': 50,         # [km]
    'channel_B_loss': 0.2,          # [dB/km]
    'channel_B_speed': 3e5,         # [km/s]
    'memory_T1': 1.0e4,             # [ns]
    'memory_T2': 0.5e4,             # [ns]
    'memory_reset_period': 1000,      # cycles of internal clock
    'memory_reset_duration': 50,    # cycles of internal clock
    'probability_detection': 100     # probability of successful detection after interacting with memory
}

memory_depths = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,30,40,50]
attempts = 1000
iterations = 1

create_plot(sim_params, attempts, iterations, memory_depths)
ns.sim_reset()